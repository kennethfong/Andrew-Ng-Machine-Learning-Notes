# 异常检测 Anomaly Detection

标签（空格分隔）： Anomaly_Detection Unsupervised_Learning Gaussian_Distribution

---

###1. 定义
　　给定一组正常样本，根据样本的分布进行建模，之后用其对测试样本进行判断，如果概率低于给定的正常阈值$\varepsilon$则标记为异常，否则标记为正常。

###2. 高斯（正态）分布
　　$X \sim \mathcal{N}(\mu, \sigma^2)$ 表示X服从（distributed as）正态分布，$\mu$表示均值，$\sigma^2$表示方差。
$$P(X; \mu,\sigma^2) = \frac 1 {\sqrt{2\pi}\sigma} exp(-\frac {(x - \mu)^2}{2\sigma^2})$$
![gaussian_distribution](http://97.64.17.179:8615/ml/gaussian_distribution.png)

#### 参数估计
　　有一个数据集$x^{(1)},x^{(2)},\cdots,x^{(m)} \ \ x^{(i)}\in \Bbb{R}$，根据其在x轴上的分布情况猜测它服从正态分布，则估计参数的计算方式如下：
　　$\mu = \frac 1 m \sum^m_{i=1}x^{(i)},\ \ \sigma^2 = \frac 1 m \sum^m_{i=1}(x^{(i)} - \mu)^2$
　　
###3. 密度估计 Density estimation
　　估计P(x)的分布问题通常被称为密度估计问题，由此得到的异常检测算法如下：
　　- 选择与异常相关的特征${x_1,x_2,\cdots,x_n}$
　　- 对于每一类特征值，都假设其服从正态分布，并计算参数$\mu_1,\cdots,\mu_n,\sigma^2_1,\cdots,\sigma^2_n$:
　　　　$\mu_j = \frac 1 m \sum^m_{i=1}x_j^{(i)}, \ \ \sigma^2_j = \frac 1 m \sum^m_{i=1}(x_j^{(i)} - \mu_j)^2$
　　- 对于一个新的样本x，计算p(x)：
$$p(x) = \prod_{j=1}^np(x_j;\mu_j,\sigma_j^2) = \prod^n_{j=1}\frac 1 {\sqrt{2\pi}\sigma_j}exp(-\frac {(x_j-\mu_j)^2}{2\sigma^2_j})$$
　　- 预先定义概率$\varepsilon$，如果p(x)$\lt\varepsilon$则标记为异常

###4. 异常检测系统的构建和评估
　　在构建异常检测系统时需要一些已经标记过的数据，比如通常是大量标记为正常的数据（比如10000条）和少量异常数据（比如50条），然后将其划分为训练集、交叉验证集和测试集。划分数据的方式一般为将正常的数据按6:2:2的比例进行划分，然后将异常数据的一半放入交叉验证集，另一半放入测试集。当然也有人按6:4的比例划分正常数据，4的部分既做交叉验证集也做测试集，但是不推荐这么做。
　　具体的步骤如下：
　　- 通过训练集的$\{x^{(1)},\cdots,x^{(m)}\}$用高斯模型拟合出p(x)
　　- 对交叉验证集/测试集上的样本x，预测：
　　　　$ y= \begin{cases} 1, & \text {if p(x) < $\varepsilon$ (异常)} \\ 0, & \text{if p(x) $\geq$ $\varepsilon$ (正常)} \end{cases} $
　　- 由于标记异常的数据较少，交叉验证集是偏斜的，需要通过True positive、False positive、False negative、True negative、Precision、Recall、$F_1-score$等指数或者维度来判断算法是否足够有效
　　- 对于参数$\varepsilon$，可以通过多次调整$\varepsilon$的值并计算$F_1-score$的值，找到使$F_1-score$最大的$\varepsilon$
　　- 最后用测试集验证算法是否确实有效

###5. 异常检测 vs. 监督学习
　　选择异常检测的原因：
　　- 数量非常小的正样本（异常，即y=1）（比如0~20个）
　　- 数量非常大的负样本（y=0）
　　- 异常种类非常多，而因为总的异常数量非常小，很难从中学习出异常，并且对于新异常很难适应；但是对正常样本（y=0）来说，高斯模型可以相对很容易的进行建模
　　选择监督学习的原因：
　　- 正负样本的数量都很大
　　- 能有足够的正样本（异常）保证可以从中学习出必要的信息，后续的正样本也很好的延续了这一规则。如果样本数量足够则更倾向于使用监督学习。

###6. 如何设计/选择特征变量
　　一般来说，即使使用实际不服从高斯分布的变量来进行建模，算法也基本上可以良好的运行，但是如果对特征变量进行转化，让其变得更像是服从高斯分布一些，算法可以更好的运行。
　　一般可以尝试对特征变量取对数运算$log(x+C)$或者开方运算$x^{\frac 1 C}$，使特征变量在运算后更像高斯分布。在Octave中，预先存入变量X，使用hist(X, 50)画出50个柱子的直方图，然后依次尝试$hist(x^{\frac 1 2})$等等，直至得到合适的直方图像，然后将运算后的变量作为算法的输入。
　　另一方面，怎么才能获得有效的特征变量呢？类似于监督学习算法中的误差分析，先完整地训练出一个学习算法，然后在一组交叉验证集上运行算法，找出那些预测出错的样本，分析这些样本看看能否找到一些其他的特征变量来帮助学习算法区分这些出错的样本，使算法在交叉验证集上表现的更好。
　　另外，有一个经验：通常选择一些取值不会特别大也不会特别小的特征变量。比如在服务器故障时，可能CPU占用很高，但是网络带宽正常，而一般情况下高负载服务器可能CPU和网络带宽都很高。那么可以把CPU占用除以网络带宽作为一个特征变量。通过类似这样的方式，将不同特征组合起来可以对应不同的异常现象。
　　
###7. 多元高斯分布
　　多元高斯分布可以用来解决一些高斯分布无法很好解决的问题。下面简单的说明一下：
![multivariate_gaussian_distribution](http://97.64.17.179:8615/ml/multivariate_gaussian_distribution.png)
　　在上图中，橙色叉标记表示正常样本，左上角的绿色叉标记表示一个异常样本。包裹橙色叉的蓝圈表示实际用来拟合高斯分布的数据在实际情况下可能的概率范围，而红圈表示根据橙色样本计算的高斯分布的概率范围。那么可以发现，绿色异常样本出现在了红圈内，即算法会认为这个样本是正常的，与实际产生了偏差。
　　算法具体如下：
　　- 需要参数$\mu \in \Bbb{R}^n, \Sigma \in \Bbb{R}^{n \times n}$(协方差矩阵)
　　- x的概率分布为：
　　$\large p(x;\mu,\Sigma) = \frac 1 {(2\pi)^{\frac n 2}|\Sigma|^{\frac 1 2}} exp \left(- \frac 1 2 (x - \mu)^T\Sigma^{-1}(x - \mu)\right)$
　　- 对于给定的训练集$x^{(1)},x^{(2)},\cdots,x^{(m)}$，计算估计值参数$\mu,\Sigma$：
　　$\mu = \frac 1 m \sum^m_{i=1}x^{(i)}, \ \Sigma = \frac 1 m \sum^m_{i=1}(x^{(i)} - \mu)(x^{(i)} - \mu)^T$
　　如上就得到了p(x)的概率分布，之后对于一个新样本x，根据上述公式计算p(x)的值，根据计算结果是否小于预定概率$\varepsilon$来判断是否属于异常样本。
　　高斯分布的等高线是沿着轴向的，而多元高斯分布则可以根据$\Sigma$的值来改变形状，当$\Sigma$的非对角线元素都为0时就与一般的高斯分布一致了。
　　与普通模型的对比：
|高斯分布 |多元高斯分布|
|---------|----------- |
|$p(x_1;\mu_1,\sigma_1^2) \times \cdots \times p(x_n;\mu_n,\sigma_n^2)$|$p(x;\mu,\Sigma) = \frac 1 {(2\pi)^{\frac n 2}|\Sigma|^{\frac 1 2}} exp \left(- \frac 1 2 (x - \mu)^T\Sigma^{-1}(x - \mu)\right)$|
|需要手动创建模型，比如如果$x_1$和$x_2$有很高的相关性，需要手动建立比如$x_3 = x_1/x_2$的特征|可以自动的捕捉特征之间的相关性|
|运算量更小，适用于n很大的情况，即特征变量的种类很多，比如n=100000|运算量更大，$\Sigma \in \Bbb{R}^{n\times n}$，矩阵运算|
|训练集较小（比如m=50或者100）也可以工作的很好|m必须大于n|
　　经验来说一般只有m比n大很多（比如m是10倍的n）的情况下才会使用多元高斯分布。如果在使用多元高斯分布时发现协方差矩阵$\Sigma$是奇异矩阵，一般有两种情况，一是没有满足m大于n的条件，二是有冗余特征变量（线性相关的特征变量）。