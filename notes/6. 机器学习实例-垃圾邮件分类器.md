# 机器学习实例-垃圾邮件分类器

标签（空格分隔）： Supervised_Learning

---
　　既然是要给邮件分类，那么这个问题属于监督学习。
### 怎么构建特征
　　比如列出一些标志性的单词，从这些单词能够区分垃圾邮件和非垃圾邮件。收集的方式可以是先收集一定数量m的邮件，标记好哪些是垃圾邮件哪些不是，然后分析这些邮件，分别找出垃圾邮件和非垃圾邮件中出现频次高的n个单词，n一般介于10000和50000之间，这样就有了n个特征值；在分析邮件时将特征值出现的记为1，不出现的记为0，于是可以得到m个n维向量作为数据集，对应邮件是否是垃圾邮件作为y的值。需要注意的是，一些同义词、近义词、一封邮件多次出现的次可以认为只有一个词。
　　有些垃圾邮件采用比较特殊的方式，比如单词拼写错误、故意用数字代替字母等等，这种情况可以在判断时进行纠正，或者是纳入特征并采用较复杂的算法来训练。
　　分析邮件的过程不仅针对邮件的正文，有时候邮件来源的email地址也会有一些明显的词汇出现，可以当做特征的一部分。
　　%Project Honey Pot%

### Error Analysis 误差分析
　　解决机器学习问题推荐的方式是这样的：
　　* 从一个简单的算法开始，快速实施，并在交叉验证集上尽早测试；
　　* 绘制学习曲线来确定是否有更多的数据，更多的特征等会有所帮助；
　　* 手动检查交叉验证集中的错误例子，尝试找出这些错误的公共特征，或者说尝试找到新的方式（比如新的特征）能区分这些错误，使算法更好的执行。

　　故这种类型的误差分析本质上是手动检测的过程，所以需要从小的、简单的算法开始。
　　另外，将错误结果转化为数值来进行判断很重要，否则很难从直觉评估算法性能。例如，如果使用“词干”，即将不同形式（比如fail/failing/failed）的单词作为一个单词处理（fail），并获得3％的错误率而不是5％，那么就应该将其添加至模型中。然而，如果试图区分大写字母和小写字母，最终却得到3.2％而不是3％的错误率，那么就应该避免使用这个新特征。故应该尝试新的东西，为错误率得到一个数值，根据结果再来决定是否要保留新的特征。
　　
### Skewed Classes 偏斜类问题
　　使用合适的误差度量值，会对算法产生微妙的影响。偏斜类问题是指几种类别之间的比例比较的极端，比如在癌症诊断问题中，往往99%的诊断结果都是正常，仅仅有1%的是患了癌症。在这样的问题中，如果算法总是预测没有患癌症，能够获得很高的正确率，但是却不能有效的判断癌症，不能认为是个好的算法。为了能正确判断这类问题的算法，需要用其他的方式进行判断。
　　对于二分问题：
![precisioin_recall](http://97.64.17.179:8615/ml/precision_recall.png)
　　定义：
　　查准率（precision）：预测为真的内容中确实为真的内容的比例，即
　　precision = true positive /(true positive + false positive)
　　召回率（recall）：在所有为真的数据中被预测为真的内容的比例，即
　　recall = true positive / (true positive + false negative)
　　在偏斜类问题中，如果算法既有较高的查准率又有较高的召回率，则认为算法是一个好的算法。
　　
　　但是有的时候往往查准率和召回率不能兼得，比如在二分问题中，把临界值调高，$h>0.9$时才认为是真，则能够得到较高的查准率，却只能得到较低的召回率；把临界值调低，$h>0.3$时就认为是真，则会得到较高的召回率，却只能得到较低的查准率。实际需要根据需求来决定是需要高查准率还是高召回率。
　　结合查准率和召回率一起来判断算法优劣时，查准率和召回率的平均值不是一个好的判断方式。通过$F_1$值来判断会比较好：
$$F_1 = 2 \frac {precision \times recall} {precision + recall}$$

### 大量数据对算法的作用
　　“It's not who has the best algorithm that wins, it's who has the most data.”
　　- 算法本身很复杂，能够拟合很多参数，不太可能过拟合
　　- 特征值x包含了足够的信息来帮助准确的预测y
　　
　　
　　



