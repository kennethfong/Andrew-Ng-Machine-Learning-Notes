# Logistic Regression 逻辑回归

tags： Logistic_Regression Classification Supervised_Learning Gradient_Descent

---
<!-- TOC -->

- [Logistic Regression 逻辑回归](#logistic-regression-逻辑回归)
    - [1. 概述](#1-概述)
        - [Logistic Function](#logistic-function)
        - [Decision Boundary决策边界](#decision-boundary决策边界)
    - [2. Cost Function](#2-cost-function)
    - [3. Gradient Descent](#3-gradient-descent)
        - [算法优化](#算法优化)
    - [4. 多分类问题（one-vs-all）](#4-多分类问题one-vs-all)

<!-- /TOC -->

---

## 1. 概述
　　用于解决监督学习中的分类（Classification）问题。  
### Logistic Function  
　　又名Sigmod Function，函数及图像如下：  
$$g(z) = \frac {1}{1+e^{-z}}$$
![logistic_function](../img/logistic_function.png)  
　　该函数将所有实数映射到(0,1)区间内，这对于分类问题来说很合适。  
　　令$z = \theta^Tx$（将线性回归代入），则有：
$$h_\theta(x) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}}$$  
把$h_\theta(x)$看做是概率的话，则$h_\theta(x) = 0.7$代表着有70%的概率得到1的输出。从这种看法来说：  
$$h_\theta(x) = P(y = 1|x;\theta) = 1 - P(y = 0|x;\theta) \\\\
P(y = 0|x;\theta) + P(y = 1|x;\theta) = 1$$  
从函数图像可以得到明显的几个性质：  
$z = 0,e^z = 1 \implies g(z) = 1/2$  
$z \to \infty,e^{-\infty} \to 0 \implies g(z) = 1$  
$z \to -\infty,e^{\infty} \to \infty \implies g(z) = 0$  

### Decision Boundary决策边界  
　　对于两分类问题来说，决策边界将分类内容分成y=0和y=1两部分，是假设函数（hypothesis function）的一个属性。  
如果将0.5作为零界点，即  
$h_\theta(x) \geq 0.5 \to y = 1$  
$h_\theta(x) \lt 0.5 \to y = 0$，则有  
$\theta^Tx \geq 0 \implies y = 1$  
$\theta^Tx \lt 0 \implies y = 0$  

## 2. Cost Function  
　　由于使用logistic function对线性相关的预测函数进行了处理，使得结果可能有很多局部最小值，即结果不是一个凸函数，所以不能套用线性相关的cost function，对于logistic regression的cost function如下：  
$$J(\theta) = \frac 1 m \sum^{m}\_{i = 1}Cost(h_\theta(x^{(i)}),y^{(i)}) \\\\  
Cost(h_\theta(x), y) = -log(h_\theta(x)) \quad if \quad y = 1 \\\\  
Cost(h_\theta(x), y) = -log(1 - h_\theta(x)) \quad if \quad y = 0$$  
其中-log(x)和-log(1-x)的图像分别如下：  
![-log(x)](../img/-log\(x\).png)  ![-log(1-x)](../img/-log\(1-x\).png)  
这样的cost function是一个凸函数。  
　　将上方的cost function进行合并，则有：  
$$\large J(\theta)=-\frac {1}{m}\sum^m_{i=1}[y^{(i)}log(h_\theta(x^{(i)})) + (1-y^{(i)})log(1-h_\theta(x^{(i)}))]$$  
　　Regularization形式：  
$$\large J(\theta) = - \frac{1}{m} \sum_{i=1}^m [ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2$$  
　　添加Regularization参数的目的同样是为了避免过拟合，见评估学习算法部分。  
　　向量写法：  
$$\large h=g(X\theta) \\  
\large J(\theta) = \frac{1}{m} · (-y^Tlog(h) - (1-y)^Tlog(1-h)) + \frac {\lambda}{2m}\sum_{j=1}^n \theta_j^2$$  

## 3. Gradient Descent  
　　算法的一些说明见linear regression。针对logistic regression：  
　　repeat {   
　　　　$\large \theta_j := \theta_j - \frac\alpha m \sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$  
　　}  
　　Regularization 形式：  
　　repeat {  
　　　　$\large \theta_0 := \theta_0 - \frac\alpha m \sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})x_0^{(i)}$  
　　　　$\large \theta_j := \theta_j - \alpha[\frac 1 m \sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)} + \frac \lambda m \theta_j]$　　j=1,2,3...n  
　　}  
　　向量形式为：$令\mathop{\theta'} = \theta,并令\mathop{\theta'}(1) = 0$  
$$\large \theta:=\theta-\frac \alpha m X^T (g(X\theta) - \overrightarrow y) + \frac \lambda m \mathop{\theta'}$$  
### 算法优化  
　　在Octave中，有Conjugate gradient、BFGS、L-BFGS等算法在一定程序上更优于Gradient Descent（比如自动选择学习速率$\alpha$，收敛更快等等），可以在使用时进行替代。Octave中有一个函数为fminunc，称之为无约束最小化函数，其内部可以使用更高效的算法来获得最佳的解。  
　　首先，需要完成costFunction函数的编写，返回函数本身和偏导数：  
``` 
function [jVal, gradient] = costFunction(theta)
    jVal = [...code to compute J(theta)...];
    gradient = [...code to compute derivative of J(theta)...];
end
``` 
　　其次，使用optimset函数设置运行参数：  
``` 
options = optimset('GradObj', 'on', 'MaxIter', 100);
``` 
　　最后，调用fminunc函数进行计算：  
``` 
[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);
``` 
计算返回结果中的optTheta表示最优的theta值，functionVal表示costFunction在最优theta下的计算结果，exitFlag表示costFunction函数是否已经收敛（1表示收敛，0表示未收敛）。  

## 4. 多分类问题（one-vs-all）
　　Logistic regression适用于多分类问题，这里使用的是一个叫“one-vs-all”的算法。简单来说，就是分别对每个类别看成二分类问题，对n个分类分别进行n次二分类计算，得到最终的假设函数。判断时，分别用每个决策器去计算，得到概率最大的那个就是预测结果。  
　　　　$y \in {0,1...n}$   
　　　　$h_\theta^{(0)}(x) = P(y = 0|x;\theta)$   
　　　　$h_\theta^{(1)}(x) = P(y = 1|x;\theta)$   
　　　　$...$  
　　　　$h_\theta^{(n)}(x) = P(y = n|x;\theta)$   
　　　　$prediction = max(h_\theta^{(i)}(x))$  

