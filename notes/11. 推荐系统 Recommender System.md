# 推荐系统 Recommender System

标签（空格分隔）： Recommender_System Unsupervised_Learning

---

###1. 简述
　　讨论推荐系统的两个原因：一是推荐系统是机器学习的一个重要应用，很多公司都有相关的需求；二是如何能让算法自动学习到一组优良的特征量可以说是机器学习中的一种宏大的想法，而推荐系统就是这种情况的一个例子。
　　这里使用一个预测电影评分的例子。用户可以为他喜欢的电影打分，打分范围为0~5星。现在有5个电影和4位用户：
|　|Alice|Bob|Carol|Dave|
|--|---|---|---|---|
|Love at last|5|5|0|0|
|Remance forever|5|-|-|0|
|Cute puppies of love|-|4|0|-|
|Nonstop car chases|0|0|5|4|
|Swords vs. karate|0|4|5|-|
　　引入符号：
　　$n_u$：用户数
　　$n_m$：电影数
　　$r(i,j)$：如果用户j给电影i评分则为1
　　$y^{(i,j)}$：用户j给电影i的评分
　　所以推荐系统问题就是给定$r(i,j)$和$y^{(i,j)}$的值，关注没有电影评分的地方，通过算法预测这些地方应该是什么值，然后根据预测的结果向用户推荐电影。
　
###2. 基于内容的算法
　　假设我们拥有电影的一些特征值，比如爱情成分或者动作成分，比如在上面的例子中，我们有如下特征：
|　|$x_1$(romance)|$x_2$(action)|
|--|---|---|
|Love at last|0.9|0|
|Remance forever|1.0|0.01|
|Cute puppies of love|0.99|0|
|Nonstop car chases|0.1|1.0|
|Swords vs. karate|0|0.9|
　　令$x_0 = 1$，则对于电影《Love at last》来说，特征为$x^{(1)} = \begin{bmatrix} 1 \\ 0.9\\ 0 \end{bmatrix}$。其他电影的特征值同理。
　　将对每个用户评分的预测都当做一个独立的线性回归问题，即根据特征值和已有的评分训练出每个用户独立的θ，然后再用这个参数预测没有评分的电影的评分。
　　算法的形式描述如下：
　　- 定义如下符号：
　　　　$r(i,j) = 1$ 表示用户j给电影i打了分（否则为0）
　　　　$y^{(i,j)}$ 表示用户j给电影i打的分数
　　　　$\theta^{(j)}$ 表示用户j的参数向量
　　　　$x^{(i)}$表示电影i的特征向量
　　　　$(\theta^{(j)})^T(x^{(i)})$ 表示用户j对电影i的预测公式
　　　　$m^{(j)}$ 表示用户j打分的电影的数量
　　- 根据线性回归，计算用户j的参数$\theta^{(j)}$：
$$\large min_{\theta^{(j)}}\frac 1 2 \sum_{i:r(i,j) = 1}\left((\theta^{(j)})^Tx^{(i)} - y^{(i,j)}\right)^2 + \frac \lambda 2\sum^n_{k=1}(\theta^{(j)}_k)^2$$
　　这里不同于之前的线性回归的地方是，去掉了除数中的样本数量m，但实际对计算结果没有影响。
　　- 由上面的公式可得，对于所有用户的参数$\theta^{(1)},\theta^{(2)},\cdots,\theta^{(n_u)}$来说，需要让所有参数最小化：
$$\large min_{\theta^{(1)},\cdots,\theta^{(n_u)}}\frac 1 2 \sum^{n_u}_{j=1}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)} - y^{(i,j)}\right)^2 + \frac \lambda 2 \sum^{n_u}_{j=1}\sum^n_{k=1}(\theta^{(j)}_k)^2$$
　　- 使上面的式子最小化可以使用梯度下降：
$$\theta^{(j)}_k := \theta^{(j)}_k - \alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})x^{(i)}_k\ (for\ k = 0) \\
\theta^{(j)}_k := \theta^{(j)}_k - \alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})x^{(i)}_k + \lambda\theta^{(j)}_k\right)\ (for\ k \neq 0)$$
　　当然也可以使用类似的更高级的算法比如聚类下降或者L-BFGS等来最小化代价函数。

###3. 协同过滤
　　在2中的算法假设了电影的特征值是已经拥有的，而实际上往往并没有这种数据，即使一个人一个人去采访，也很难让他们花时间看完每一部电影然后说出这部电影浪漫指数有多少，动作指数有多少。
　　现在换一种思路，依然是采访一些用户，但是这次只需要他们表明是否喜欢浪漫的电影，是否喜欢动作电影，这个结果作为$\theta^{(j)}$的值。如果能从用户那得到θ值，那么理论上也就可以推测出每部电影的$x_1、x_2$特征值。根据这个思路，转化为在知道一些用户的偏好参数$\theta^{(1)},\theta^{(2)},\cdots,\theta^{(n_u)}$下，想要推测出某个电影的特征$x^{(i)}$，需要最小化如下式子：
$$\large min_{x^{(i)}} \frac 1 2 \sum_{j:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)} - y^{(i,j)}\right)^2 + \frac \lambda 2 \sum^n_{k=1}(x^{(i)}_k)^2$$
　　那么需要推测出一些电影的特征$x^{(1)},\cdots,x^{(n_m)}$时，则需要最小化如下式子：
$$\large min_{x^{(1)},\cdots,x^{(n_m)}}\frac 1 2 \sum^{n_m}_{i=1}\sum_{j:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)} - y^{(i,j)}\right)^2 + \frac \lambda 2 \sum^{n_m}_{i=1}\sum^n_{k=1}(x^{(i)}_k)^2$$

　　结合上面的两种方式，如果有用户接受调查，就可以学习出电影的特征；如果有电影的特征，就能学习出用户的倾向。这看起来似乎是一个鸡生蛋蛋生鸡的问题。实际上在开始可以做的是随机猜测θ的值，一旦猜测出了θ的值，就可以根据上面的方式交替的进行学习，不停的优化θ、x、θ、x……算法会收敛到一组合理的特征以及一组合理的对不同用户参数的估计。

　　除了这样交替的运算，也可以有更好的方式。如果能同时计算出θ和x，那么计算过程会方便很多。将上方两个对用户的代价函数和对电影的代价函数结合起来，有：
$$J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)}) = \frac 1 2 \sum_{(i,j):r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})^2 + \frac \lambda 2 \sum^{n_m}_{i=1}\sum^n_{k=1}(x^{(i)}_k)^2 + \frac \lambda 2 \sum^{n_u}_{j=1}\sum^n_{k=1}(\theta^{(j)}_k)^2$$
　　具体的算法：
　　- 将$x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)}$初始化为随机小的值
　　- 通过梯度下降或者其他高级算法来使上面的代价函数最小化：
　　$x^{(i)}_k := x^{(i)}_k - \alpha(\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})\theta^{(j)}_k + \lambda x^{(i)}_k)$
　　$\theta^{(j)}_k := \theta^{(j)}_k - \alpha(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)} - y^{(i,j)})x^{(i)}_k + \lambda \theta^{(j)}_k)$
　　- 之后通过运算到的用户参数θ和对应电影的特征x预测该用户对该电影的评分$\theta^Tx$
　　需要注意的是，上面的算法不需要像其他算法一样添加$x_0和\theta_0$，x和θ是n维向量而非n+1维向量，原因在于需要的特征算法会自己从中学习到，而不需要额外的添加。

####低秩矩阵分解（Low Rank Matrix Factorization）
　　按向量化的想法，将各用户对各电影的评分用向量形式表示，比如在1中的例子中，向量表示为$Y = \begin{bmatrix} 5 & 5 & 0 & 0 \\ 5 & ? & ? & 0 \\ ? & 4 & 0 & ? \\ 0 & 0 & 5 & 4 \\ 0 & 0 & 5 & 0 \end{bmatrix}$，按上方所述$\theta^Tx$表示用户对电影评分的预测，则预测结果矩阵实际上形如$\begin{bmatrix} (\theta^{(1)})^T(x^{(1)}) & \cdots & (\theta^{(n_u)})^T(x^{(1)}) \\ \vdots & \vdots & \vdots \\ (\theta^{(1)})^T(x^{(n_m)}) & \cdots & (\theta^{(n_u)})^T(x^{(n_m)}) \end{bmatrix} = X\Theta^T$，其中$X = \begin{bmatrix} — (x^{(1)})^T —\\ \vdots \\ — (x^{(n_m)})^T — \end{bmatrix}, \Theta = \begin{bmatrix} — (\theta^{(1)})^T —\\ \vdots \\ — (\theta^{(n_u)})^T — \end{bmatrix}$，向量化的算法即低秩矩阵分解。
　　
####确定电影之间的相似性
　　实际上在通过上面的算法计算出了电影的特征之后，可能也很难理解这些特征所代表的含义。电影之间的相似性也许可以方便判断对于评分的预测是否准确，即A电影与B电影相似，则用户在喜欢A电影的同时也有很大的可能性喜欢B电影。判断相似性很难从特征含义上入手，那么可以通过特征之间的距离，即$\|x^{(i)} - x^{(j)}\|$来判断，距离越小则越相似。根据这个特点，想要推荐给用户电影时可以根据特征之间的相似性来推荐。

####均值归一化（Mean Normalization）
　　根据协同过滤算法中的代价函数，如果一个新用户没有对任何电影评分过，那么通过算法计算出的这个用户的θ的各项应该都是0。这样的结果算法是没有办法向这个用户推荐电影的，解决这个问题的一个方法就是均值归一化。
　　具体做法，还是用1中的例子，添加一个新用户Eve，她没有对任何电影评分过，所有评分的矩阵表示为Y：$Y = \begin{bmatrix} 5 & 5 & 0 & 0 & ? \\ 5 & ? & ? & 0 & ? \\ ? & 4 & 0 & ? & ? \\ 0 & 0 & 5 & 4 & ? \\ 0 & 0 & 5 & 0 & ? \end{bmatrix}$，计算每个电影评分的平均值（忽略？）：$\mu = \begin{bmatrix} 2.5 \\ 2.5 \\ 2 \\ 2.25 \\ 1.25 \end{bmatrix}$，之后用$Y - \mu$计算出新的矩阵$Y'$：$Y' = \begin{bmatrix} 2.5 & 2.5 & -2.5 & -2.5 & ? \\ 2.5 & ? & ? & -2.5 & ? \\ ? & 2 & -2 & ? & ? \\ -2.25 & -2.25 & 2.75 & 1.75 & ? \\ -1.25 & -1.25 & 3.75 & -1.25 & ? \end{bmatrix}$。之后用$Y'$进行算法的运算，在运算出结果后使用$(\theta^{/(j)})^Tx^{(i)} + \mu_i$来计算出预测用户的评分。在这样的算法下，因为用户Eve的参数θ为0，故评分会被预测为：$\begin{bmatrix} 2.5 \\ 2.5 \\ 2 \\ 2.25 \\ 1.25 \end{bmatrix}$，这样推荐系统就可以根据评分对用户进行推荐，而不会因为推测新用户评分为0而没有任何推荐。故均值归一化的步骤应该作为算法开始前的初始化步骤。
　　另外如果一个电影没有任何一个人评分过，那么算法也无法为这个电影预测每个用户的评分。不过换一种角度来说，也许没有任何评分的电影也不应该被推荐给任何人。