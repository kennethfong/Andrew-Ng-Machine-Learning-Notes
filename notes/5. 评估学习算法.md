# 评估学习算法

标签（空格分隔）： Bias_Variance Supervised_Learning Neural_Network

---

###1. 拆分训练集
　　过拟合（overfitting）：训练出的假设函数对训练集拟合的很好，但是在其他数据集中拟合的很差
　　欠拟合（underfitting）:训练出的假设函数对训练集拟合的不好
　　
　　为了能更加方便的测试训练结果，可以预先对数据集进行拆分（数据集预先随机排列，打乱顺序）：
　　* 拆分为训练集（training set）和测试集（test set），比例为7:3，通过训练集对假设函数进行训练，用训练结果放在测试集中计算误差，比如对于线性回归，误差的计算方式：
$$\large J_{test}(\theta) = \frac 1 {2m_{test}}\sum_{i=1}^{m_{test}}(h_{\theta}(x^{(i)}_{test})-y^{(i)}_{test})^2$$
　　对于逻辑回归（二分类问题），误差的计算方式：
$$\large J_{test}(\theta)=-\frac 1 {m_{test}}\sum_{i=1}^{m_{test}}[y_{test}^{(i)}logh_{\theta}(x^{(i)}_{test})+(1-y_{test}^{(i)})logh_{\theta}(x_{test}^{(i)})]$$
　　* 比如在选择线性回归的多项式次数（degree）时，可以拆分为训练集（training set）、交叉验证集（cross validation set）和测试集（test set），比例为6:2:2，分别令多项式次数等于1、2、3...n，在训练集上训练，然后在交叉验证集上验证（计算误差），找到交叉验证集上误差最小的次数，最后放在测试集上验证误差，判断是否可以接受。

###2. Bias vs. Variance
　　high bias -> underfitting
　　high variance -> overfitting
　　根据上面选择多项式次数的例子，令$J_{train}(\Theta)为在训练集上的误差，$$J_{CV}(\Theta)$为在交叉验证集上的误差，则可能有如下的图像：
![bias_vs_variance](http://97.64.17.179:8615/ml/bias_vs_variance.png)
    多项式次数越高，可能对于训练集的拟合越好，所以误差越小；对训练集拟合的越好，则越可能在交叉验证集上拟合的不好，所以在交叉验证集上的误差越大，所以需要找到一个平衡点。
    此时：
    high bias(underfitting)：$J_{train}(\Theta)和J_{CV}(\Theta)$都很高，并且可能$J_{train}(\Theta) \approx J_{CV}(\Theta)$；
    high variance(overfitting)：$J_{train}(\Theta)$会比较小并且$J_{CV}(\Theta)$会比$J_{train}(\Theta)$大很多。
    
###3. Regularization
　　在线性回归和逻辑回归中都可以添加Regularization参数来防止过拟合。在引入λ后使得cost function主体部分在总结果中的比重会减小，这样在选择好合适的$\lambda$的情况下可以防止过拟合。λ选择的过大，θ会变的很小，导致假设函数无法很好的拟合数据；λ选择的过小则无法对θ起到约束作用，可能会过拟合。如何选择一个合适的$\lambda$：
　　a) 创建λ的列表，比如λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24}
　　b) 创建不同维度或者其他形式的模型
　　c) 依次根据不同的λ进行学习，得到对应不同的θ
　　d) 根据学习到的θ计算交叉验证集的误差$J_{CV}(\Theta)$（不使用Regularization参数）
　　e) 找到使$J_{CV}(\Theta)$最小的θ和λ值，并用其计算$J_{test}(\Theta)$看是否能很好的适应新数据集
　　一个$J(\theta)与\lambda$可能的关系图如下（实际可能有很多噪声）：
![regularization_lambda](http://97.64.17.179:8615/ml/regularization_lambda.png)
　　
###4. Learning Curves
　　学习曲线是指误差与训练集大小的曲线。在训练集较小的时候，很容易拟合，误差会比较小，随着训练集增大，产生的误差将会越来越大。当训练集大到一定程度时，误差将达到稳定，不再明显变化。
　　在高偏差和高方差下的学习曲线示意图分别如下（实际可能存在噪声和干扰）：
　　High bias：
![learning_curves_bias](http://97.64.17.179:8615/ml/learning_curves_bias.png)
　　当数据集比较小时，$J_{train}(\Theta)$比较小而$J_{CV}(\Theta)$比较大；当数据集比较大时，$J_{train}(\Theta)$和$J_{CV}(\Theta)$都变的比较大并且有$J_{train}(\Theta) \approx J_{CV}(\Theta)$。此时可以看到，在数据集大小增长到一定程度时，交叉验证集的误差不再减小，继续增大数据集也不会使训练结果对新的数据更有效。
　　High variance：
![learning_curves_variance](http://97.64.17.179:8615/ml/learning_curves_variance.png)
　　当数据集比较小时，$J_{train}(\Theta)$比较小而$J_{CV}(\Theta)$比较大；随着数据集的变大，$J_{train}(\Theta)$不断增大而$J_{CV}(\Theta)$不断减小，但$J_{CV}(\Theta)$依然大于$J_{train}(\Theta)$且差别很明显。如果继续增大数据集大小，$J_{CV}(\Theta)$将会继续减小，这表明增大数据集的这种措施对于高方差类型的算法有效。
　　
###5. 常用优化方式
　　High bias：
　　- 添加新的特征值
　　- 添加多项式特征
　　- 减小λ
　　High variance：
　　- 获得更多的训练数据
　　- 使用更少的特征值
　　- 增大λ
　　
　　对于神经网络，拥有更少参数的神经网络更容易欠拟合，却也更容易计算；拥有更多参数的神经网络更容易过拟合，也更不容易计算，可以通过Regularization参数（比如增大λ）来解决。默认可以使用单层隐藏层，可以分别用不同层数的隐藏层分别训练，再通过交叉验证集确定哪个模型更加合适。




